---
title: "Learning Human Utility from Video Demonstrations for Deductive Planning in Robotics"
collection: publications
permalink: /publication/2017-11-01-learning-human-utility
excerpt: 'We uncouple three components of autonomous behavior (utilitarian value, causal reasoning, and fine motion control) to design an interpretable model of tasks from video demonstrations...'
date: 2017-11-01
venue: 'Conference on Robot Learning (CoRL)'
paperurl: 'http://proceedings.mlr.press/v78/shukla17a.html'
citation: 'Shukla, N., He, Y., <b>Chen, F.</b> & Zhu, S.. (2017). Learning Human Utility from Video Demonstrations for Deductive Planning in Robotics. Proceedings of the 1st Annual Conference on Robot Learning, in PMLR 78:448-457'
---
We uncouple three components of autonomous behavior (utilitarian value, causal reasoning, and fine motion control) to design an interpretable model of tasks from video demonstrations. Utilitarian value is learned from aggregating human preferences to understand the implicit goal of a task, explaining _why_ an action sequence was performed. Causal reasoning is seeded from observations and grows from robot experiences to explain _how_ to deductively accomplish sub-goals. And lastly, fine motion control describes _what_ actuators to move. In our experiments, a robot learns how to fold t-shirts from visual demonstrations, and proposes a plan (by answering _why_, _how_, and _what_) when folding never-before-seen articles of clothing.

[Download paper here](http://proceedings.mlr.press/v78/shukla17a/shukla17a.pdf)

**Recommended citation**: Shukla, N., He, Y., Chen, F. & Zhu, S.. (2017). Learning Human Utility from Video Demonstrations for Deductive Planning in Robotics. Proceedings of the 1st Annual Conference on Robot Learning, in PMLR 78:448-457 