

<!doctype html>
<html lang="en" class="no-js">
  <head>
    

<meta charset="utf-8">



<!-- begin SEO -->









<title>Deriving the Normal Distribution - Frank Chen</title>







<meta property="og:locale" content="en-US">
<meta property="og:site_name" content="Frank Chen">
<meta property="og:title" content="Deriving the Normal Distribution">


  <link rel="canonical" href="https://kfrankc.com/posts/2018/10/19/normal-dist-derivation">
  <meta property="og:url" content="https://kfrankc.com/posts/2018/10/19/normal-dist-derivation">



  <meta property="og:description" content="In every introductory statistics class, we learned about the normal distribution, which has Probability Density Function (PDF):This looks like a fairly complicated equation, but the resulting graph (shown above) has some very cool properties (integrates to 1, represents real-valued random variables whose distributions are not known etc…). I’ve always wondered how this is derived, and I finally found some answers via great YouTube videos and online forums. I will give an overview of the derivation here, based on YouTuber Mathoma’s amazing video (linked above).Part 1: The TheoryMathoma gave a great analogy about how to understand this distribution: imagine you are throwing darts on a polar coordinate system, with the goal of hitting the center \((0,0)\). Now, given an arbitrary dart landing on coordinate \((r, \theta)\), we can also say that the coordinate is \((x, y)\) if we convert from polar to cartesian.We have to make a couple assumptions here before moving forward. First, we assume that \(x\) and \(y\) are statistically independent. Second, we assume that the PDF is rotationally invariant, which means the distribution of where my dart lands only depends on the distance \(r\), of the dart to the center.With those assumptions, I can define PDF \(\varphi(r) = f(x)f(y)\). This can be rewritten asNext, suppose \(y=0\). We will then have$$\begin{align*}    \varphi(\sqrt{x^2 + 0^2}) &amp;= f(x)f(0)\\    \varphi(x) &amp;= f(x)\lambda, \text{ where $\lambda$ is a constant}\end{align*}$$Plugging this back into Eq \ref{eq2}, we haveNext, we will determine the expression for $f(x)$. First, we rewrite Eq \ref{eq3} asFor simplicity in analyzing the equation, define $g(x) = \frac{f(x)}{\lambda}$. We now haveWhat kind of function should $g$ be so that Eq \ref{eq4} is valid? Upon some inspection, we can see that $g$ should be an exponential function. Example: suppose we have $h(x) = e^x$, then $h(x)h(y) = e^xe^y = e^{x+y} = h(x+y)$. Similarly, let $g(x) = e^{Ax^2}$, where $A$ is a constant.$$\begin{align*}    g(x)g(y) &amp;= e^{Ax^2}e^{Ay^2}\\    &amp;= e^{A(x^2 + y^2)}\\    &amp;= e^{A(\sqrt{x^2 + y^2})^2}\\    &amp;= g(\sqrt{x^2 + y^2})\end{align*}$$In turn, our PDF $f$ should bePlotting this equation out with $A=-1$ (more on why $A$ is negative later) and $\lambda=1$, we see that it takes a gaussian form!Part 2: Massaging the EquationThe remainder of this derivation serves to massage Eq \ref{eq5} into the class of gaussians we are interested in, the normal gaussian.First, we introduce a constraint on the function: since we are modeling probability, it makes sense for $f(x)$ to integrate to $1$.Instead of using constant $A$, we will set $A = -h^2$, where $h$ is a constant variable. There are several reasons for this: First, it makes sense for $A$ to be negative, because we want this function (which models the probability) to decrease as we move to $+\infty$. Second, the $-h^2$ form will help when we do the integration.We determine the value of $h^2$:$$\begin{align*}    \int_{-\infty}^{\infty}\lambda e^{-h^2x^2}dx &amp;= 1\\    \lambda\int_{-\infty}^{\infty}e^{-h^2x^2}dx &amp;= 1\\\end{align*}$$Perform u-substitution, with $u = hx$, $du = hdx$, and $dx = \frac{1}{h}du$. We now getInterestingly, the integral in Eq \ref{eq6} is actually famous (it has a name!). The Gaussian integral, also known as the Euler-Poisson integral, is equal to $\sqrt{\pi}$ (refer to link for the integral computation).We can now compute $h^2$:$$\begin{align*}    \frac{\lambda}{h}\sqrt{\pi} &amp;= 1\\    h &amp;= \lambda \sqrt{\pi}\\    h^2 &amp;= \lambda^2\pi\end{align*}$$Eq \ref{eq5} becomesIf we plot $f(x)$ using different $\lambda$ values, we see that as $\lambda$ increases, the variance $\sigma^2$ decreases, since more of the area is accumulated at $x=0$. See plots for $\lambda=1$, $\lambda=2$, $\lambda=3$ as examples.Next, we need to find the relationship between $\lambda$ and variance $\sigma^2$. From definition of variance, we see that $Var(X) = E[(X - \mu)^2]$. In our case, $\mu$ is 0, so we have:$$\begin{align*}    Var(x) = \sigma^2 &amp;= \int_{-\infty}^{\infty}x^2 \lambda e^{-\pi \lambda^2x^2}dx \\    &amp;= \lambda \int_{-\infty}^{\infty} x \cdot x \cdot e^{-\pi \lambda^2x^2}dx\end{align*}$$We will evaluate this integral via integration by parts. Recall thatLet $u = x$, $du = dx$, $dv = xe^{-\pi \lambda^2x^2}dx$, $v = -\frac{1}{2\pi\lambda^2}e^{-\pi \lambda^2x^2}$:$$\begin{align*}    Var(x) = \sigma^2 &amp;= \lambda \left(x\left(-\frac{1}{2\pi\lambda^2}e^{-\pi \lambda^2x^2}\Biggr|_{-\infty}^{\infty}\right) - \int_{-\infty}^{\infty}\left(-\frac{1}{2\pi\lambda^2}e^{-\pi \lambda^2x^2}\right)dx\right)\\    &amp;= \lambda \left((0) + \int_{-\infty}^{\infty}\frac{1}{2\pi\lambda^2}e^{-\pi \lambda^2x^2}dx\right)\\    &amp;= \frac{1}{2\pi\lambda^2}\int_{-\infty}^{\infty}\lambda e^{-\pi \lambda^2x^2}dx\end{align*}$$The reason we switched the position of $\lambda$ and $\frac{1}{2\pi\lambda^2}$ is so we can massage the integral to be the form of the gaussian PDF, which we know integrates to 1. Now, with the equation simplified, we can solve for $\lambda$ in terms of $\sigma^2$.$$\begin{align*}    \sigma^2 &amp;= \frac{1}{2\pi\lambda^2}\\    \lambda^2 &amp;= \frac{1}{\sigma^2 2\pi}\\    \lambda &amp;= \frac{1}{\sqrt{2\pi\sigma^2}}\end{align*}$$$\lambda$ and $\sigma$ are inversely proportional, as expected. We can plug in our result here back into Eq \ref{eq7}:$$\begin{align}\label{eq8}    f(x) &amp;= \frac{1}{\sqrt{2\pi\sigma^2}}e^{-\pi \left(\frac{1}{(\sqrt{2\pi\sigma^2})^2}\right)x^2}\nonumber\\    &amp;= \frac{1}{\sqrt{2\pi\sigma^2}}e^{-\frac{x^2}{2\sigma^2}}\end{align}$$We are almost done. The above equation has mean $\mu = 0$, but if we want to represent $f(x|\mu, \sigma^2)$, we need to add in $f(x-\mu)$. Therefore, our general PDF equation for the normal distribution is:Eq \ref{eq9} matches Eq \ref{eq1}, and we are now done. $\blacksquare$">





  

  





  <meta property="og:type" content="article">
  <meta property="article:published_time" content="2018-10-19T00:00:00-07:00">








  <script type="application/ld+json">
    {
      "@context" : "http://schema.org",
      "@type" : "Person",
      "name" : "Frank Chen",
      "url" : "https://kfrankc.com",
      "sameAs" : null
    }
  </script>






<!-- end SEO -->


<link href="https://kfrankc.com/feed.xml" type="application/atom+xml" rel="alternate" title="Frank Chen Feed">

<!-- http://t.co/dKP3o1e -->
<meta name="HandheldFriendly" content="True">
<meta name="MobileOptimized" content="320">
<meta name="viewport" content="width=device-width, initial-scale=1.0">

<script>
  document.documentElement.className = document.documentElement.className.replace(/\bno-js\b/g, '') + ' js ';
</script>

<!-- For all browsers -->
<link rel="stylesheet" href="https://kfrankc.com/assets/css/main.css">

<meta http-equiv="cleartype" content="on">
    

<!-- start custom head snippets -->

<link rel="apple-touch-icon" sizes="57x57" href="https://kfrankc.com/images/apple-touch-icon-57x57.png?v=M44lzPylqQ">
<link rel="apple-touch-icon" sizes="60x60" href="https://kfrankc.com/images/apple-touch-icon-60x60.png?v=M44lzPylqQ">
<link rel="apple-touch-icon" sizes="72x72" href="https://kfrankc.com/images/apple-touch-icon-72x72.png?v=M44lzPylqQ">
<link rel="apple-touch-icon" sizes="76x76" href="https://kfrankc.com/images/apple-touch-icon-76x76.png?v=M44lzPylqQ">
<link rel="apple-touch-icon" sizes="114x114" href="https://kfrankc.com/images/apple-touch-icon-114x114.png?v=M44lzPylqQ">
<link rel="apple-touch-icon" sizes="120x120" href="https://kfrankc.com/images/apple-touch-icon-120x120.png?v=M44lzPylqQ">
<link rel="apple-touch-icon" sizes="144x144" href="https://kfrankc.com/images/apple-touch-icon-144x144.png?v=M44lzPylqQ">
<link rel="apple-touch-icon" sizes="152x152" href="https://kfrankc.com/images/apple-touch-icon-152x152.png?v=M44lzPylqQ">
<link rel="apple-touch-icon" sizes="180x180" href="https://kfrankc.com/images/apple-touch-icon-180x180.png?v=M44lzPylqQ">
<link rel="icon" type="image/png" href="https://kfrankc.com/images/favicon-32x32.png?v=M44lzPylqQ" sizes="32x32">
<link rel="icon" type="image/png" href="https://kfrankc.com/images/android-chrome-192x192.png?v=M44lzPylqQ" sizes="192x192">
<link rel="icon" type="image/png" href="https://kfrankc.com/images/favicon-96x96.png?v=M44lzPylqQ" sizes="96x96">
<link rel="icon" type="image/png" href="https://kfrankc.com/images/favicon-16x16.png?v=M44lzPylqQ" sizes="16x16">
<link rel="manifest" href="https://kfrankc.com/images/manifest.json?v=M44lzPylqQ">
<link rel="mask-icon" href="https://kfrankc.com/images/safari-pinned-tab.svg?v=M44lzPylqQ" color="#000000">
<link rel="shortcut icon" href="/images/favicon.ico?v=M44lzPylqQ">
<meta name="msapplication-TileColor" content="#000000">
<meta name="msapplication-TileImage" content="https://kfrankc.com/images/mstile-144x144.png?v=M44lzPylqQ">
<meta name="msapplication-config" content="https://kfrankc.com/images/browserconfig.xml?v=M44lzPylqQ">
<meta name="theme-color" content="#ffffff">
<link rel="stylesheet" href="https://kfrankc.com/assets/css/academicons.css"/>

<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
  	TeX: {
      equationNumbers: {
        autoNumber: "AMS"
      }
    },
    tex2jax: {
      inlineMath: [ ['$','$'], ["\\(","\\)"] ],
      displayMath: [ ['$$','$$'] ],
      processEscapes: true
    }
  });
</script>
<script type= "text/javascript" src='https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/latest.js?config=TeX-MML-AM_CHTML' async></script>
<!-- end custom head snippets -->

  </head>

  <body>

    <!--[if lt IE 9]>
<div class="notice--danger align-center" style="margin: 0;">You are using an <strong>outdated</strong> browser. Please <a href="http://browsehappy.com/">upgrade your browser</a> to improve your experience.</div>
<![endif]-->
    

<div class="masthead">
  <div class="masthead__inner-wrap">
    <div class="masthead__menu">
      <nav id="site-nav" class="greedy-nav">
        <button><div class="navicon"></div></button>
        <ul class="visible-links">
          <li class="masthead__menu-item masthead__menu-item--lg"><a href="https://kfrankc.com/">Frank Chen</a></li>
          
            
            <li class="masthead__menu-item"><a href="https://kfrankc.com/portfolio/">Portfolio</a></li>
          
            
            <li class="masthead__menu-item"><a href="https://kfrankc.com/publications/">Publications</a></li>
          
            
            <li class="masthead__menu-item"><a href="https://kfrankc.com/year-archive/">Blog Posts</a></li>
          
            
            <li class="masthead__menu-item"><a href="https://kfrankc.com/assets/files/kfrankc_CV.pdf">CV</a></li>
          
            
            <li class="masthead__menu-item"><a href="https://kfrankc.com/assets/files/kfrankc_RESUME.pdf">Resume</a></li>
          
        </ul>
        <ul class="hidden-links hidden"></ul>
      </nav>
    </div>
  </div>
</div>

    





<div id="main" role="main">
  


  <div class="sidebar sticky">
  



<div itemscope itemtype="http://schema.org/Person">

  <div class="author__avatar">
    
    	<img src="https://kfrankc.com/images/kfrankc_profile.png" class="author__avatar" alt="Frank Chen">
    
  </div>

  <div class="author__content">
    <h3 class="author__name">Frank Chen</h3>
    <p class="author__bio">Program Manager at Microsoft pursuing a Masters in Data Science</p>
  </div>

  <div class="author__urls-wrapper">
    <button class="btn btn--inverse">Follow</button>
    <ul class="author__urls social-icons">
      
      
        <li><i class="fa fa-fw fa-map-marker" aria-hidden="true"></i> Microsoft, Redmond</li>
      
      
      
        <li><a href="mailto:kfrankc@uw.edu"><i class="fa fa-fw fa-envelope-square" aria-hidden="true"></i> Email</a></li>
      
      
        <li><a href="https://keybase.io/kfrankc"><i class="fa fa-fw fa-key" aria-hidden="true"></i> Keybase</a></li>
      
      
        <li><a href="https://twitter.com/kfrankc95"><i class="fa fa-fw fa-twitter-square" aria-hidden="true"></i> Twitter</a></li>
      
      
      
      
        <li><a href="https://www.linkedin.com/in/kfrankc"><i class="fa fa-fw fa-linkedin-square" aria-hidden="true"></i> LinkedIn</a></li>
      
      
      
        <li><a href="https://instagram.com/bykfrankc"><i class="fa fa-fw fa-instagram" aria-hidden="true"></i> Instagram</a></li>
      
      
      
      
        <li><a href="https://github.com/kfrankc"><i class="fa fa-fw fa-github" aria-hidden="true"></i> Github</a></li>
      
      
      
      
      
      
      
      
      
      
      
      
      
      
        <li><a href="https://scholar.google.com/citations?user=v2iJEd8AAAAJ&hl=en"><i class="ai ai-google-scholar-square ai-fw"></i> Google Scholar</a></li>
      
      
      
    </ul>
  </div>
</div>

  
  </div>


  <article class="page" itemscope itemtype="http://schema.org/CreativeWork">
    <meta itemprop="headline" content="Deriving the Normal Distribution">
    <meta itemprop="description" content="In every introductory statistics class, we learned about the normal distribution, which has Probability Density Function (PDF):This looks like a fairly complicated equation, but the resulting graph (shown above) has some very cool properties (integrates to 1, represents real-valued random variables whose distributions are not known etc…). I’ve always wondered how this is derived, and I finally found some answers via great YouTube videos and online forums. I will give an overview of the derivation here, based on YouTuber Mathoma’s amazing video (linked above).Part 1: The TheoryMathoma gave a great analogy about how to understand this distribution: imagine you are throwing darts on a polar coordinate system, with the goal of hitting the center \((0,0)\). Now, given an arbitrary dart landing on coordinate \((r, \theta)\), we can also say that the coordinate is \((x, y)\) if we convert from polar to cartesian.We have to make a couple assumptions here before moving forward. First, we assume that \(x\) and \(y\) are statistically independent. Second, we assume that the PDF is rotationally invariant, which means the distribution of where my dart lands only depends on the distance \(r\), of the dart to the center.With those assumptions, I can define PDF \(\varphi(r) = f(x)f(y)\). This can be rewritten asNext, suppose \(y=0\). We will then have$$\begin{align*}    \varphi(\sqrt{x^2 + 0^2}) &amp;= f(x)f(0)\\    \varphi(x) &amp;= f(x)\lambda, \text{ where $\lambda$ is a constant}\end{align*}$$Plugging this back into Eq \ref{eq2}, we haveNext, we will determine the expression for $f(x)$. First, we rewrite Eq \ref{eq3} asFor simplicity in analyzing the equation, define $g(x) = \frac{f(x)}{\lambda}$. We now haveWhat kind of function should $g$ be so that Eq \ref{eq4} is valid? Upon some inspection, we can see that $g$ should be an exponential function. Example: suppose we have $h(x) = e^x$, then $h(x)h(y) = e^xe^y = e^{x+y} = h(x+y)$. Similarly, let $g(x) = e^{Ax^2}$, where $A$ is a constant.$$\begin{align*}    g(x)g(y) &amp;= e^{Ax^2}e^{Ay^2}\\    &amp;= e^{A(x^2 + y^2)}\\    &amp;= e^{A(\sqrt{x^2 + y^2})^2}\\    &amp;= g(\sqrt{x^2 + y^2})\end{align*}$$In turn, our PDF $f$ should bePlotting this equation out with $A=-1$ (more on why $A$ is negative later) and $\lambda=1$, we see that it takes a gaussian form!Part 2: Massaging the EquationThe remainder of this derivation serves to massage Eq \ref{eq5} into the class of gaussians we are interested in, the normal gaussian.First, we introduce a constraint on the function: since we are modeling probability, it makes sense for $f(x)$ to integrate to $1$.Instead of using constant $A$, we will set $A = -h^2$, where $h$ is a constant variable. There are several reasons for this: First, it makes sense for $A$ to be negative, because we want this function (which models the probability) to decrease as we move to $+\infty$. Second, the $-h^2$ form will help when we do the integration.We determine the value of $h^2$:$$\begin{align*}    \int_{-\infty}^{\infty}\lambda e^{-h^2x^2}dx &amp;= 1\\    \lambda\int_{-\infty}^{\infty}e^{-h^2x^2}dx &amp;= 1\\\end{align*}$$Perform u-substitution, with $u = hx$, $du = hdx$, and $dx = \frac{1}{h}du$. We now getInterestingly, the integral in Eq \ref{eq6} is actually famous (it has a name!). The Gaussian integral, also known as the Euler-Poisson integral, is equal to $\sqrt{\pi}$ (refer to link for the integral computation).We can now compute $h^2$:$$\begin{align*}    \frac{\lambda}{h}\sqrt{\pi} &amp;= 1\\    h &amp;= \lambda \sqrt{\pi}\\    h^2 &amp;= \lambda^2\pi\end{align*}$$Eq \ref{eq5} becomesIf we plot $f(x)$ using different $\lambda$ values, we see that as $\lambda$ increases, the variance $\sigma^2$ decreases, since more of the area is accumulated at $x=0$. See plots for $\lambda=1$, $\lambda=2$, $\lambda=3$ as examples.Next, we need to find the relationship between $\lambda$ and variance $\sigma^2$. From definition of variance, we see that $Var(X) = E[(X - \mu)^2]$. In our case, $\mu$ is 0, so we have:$$\begin{align*}    Var(x) = \sigma^2 &amp;= \int_{-\infty}^{\infty}x^2 \lambda e^{-\pi \lambda^2x^2}dx \\    &amp;= \lambda \int_{-\infty}^{\infty} x \cdot x \cdot e^{-\pi \lambda^2x^2}dx\end{align*}$$We will evaluate this integral via integration by parts. Recall thatLet $u = x$, $du = dx$, $dv = xe^{-\pi \lambda^2x^2}dx$, $v = -\frac{1}{2\pi\lambda^2}e^{-\pi \lambda^2x^2}$:$$\begin{align*}    Var(x) = \sigma^2 &amp;= \lambda \left(x\left(-\frac{1}{2\pi\lambda^2}e^{-\pi \lambda^2x^2}\Biggr|_{-\infty}^{\infty}\right) - \int_{-\infty}^{\infty}\left(-\frac{1}{2\pi\lambda^2}e^{-\pi \lambda^2x^2}\right)dx\right)\\    &amp;= \lambda \left((0) + \int_{-\infty}^{\infty}\frac{1}{2\pi\lambda^2}e^{-\pi \lambda^2x^2}dx\right)\\    &amp;= \frac{1}{2\pi\lambda^2}\int_{-\infty}^{\infty}\lambda e^{-\pi \lambda^2x^2}dx\end{align*}$$The reason we switched the position of $\lambda$ and $\frac{1}{2\pi\lambda^2}$ is so we can massage the integral to be the form of the gaussian PDF, which we know integrates to 1. Now, with the equation simplified, we can solve for $\lambda$ in terms of $\sigma^2$.$$\begin{align*}    \sigma^2 &amp;= \frac{1}{2\pi\lambda^2}\\    \lambda^2 &amp;= \frac{1}{\sigma^2 2\pi}\\    \lambda &amp;= \frac{1}{\sqrt{2\pi\sigma^2}}\end{align*}$$$\lambda$ and $\sigma$ are inversely proportional, as expected. We can plug in our result here back into Eq \ref{eq7}:$$\begin{align}\label{eq8}    f(x) &amp;= \frac{1}{\sqrt{2\pi\sigma^2}}e^{-\pi \left(\frac{1}{(\sqrt{2\pi\sigma^2})^2}\right)x^2}\nonumber\\    &amp;= \frac{1}{\sqrt{2\pi\sigma^2}}e^{-\frac{x^2}{2\sigma^2}}\end{align}$$We are almost done. The above equation has mean $\mu = 0$, but if we want to represent $f(x|\mu, \sigma^2)$, we need to add in $f(x-\mu)$. Therefore, our general PDF equation for the normal distribution is:Eq \ref{eq9} matches Eq \ref{eq1}, and we are now done. $\blacksquare$">
    <meta itemprop="datePublished" content="October 19, 2018">
    

    <div class="page__inner-wrap">
      
        <header>
          <h1 class="page__title" itemprop="headline">Deriving the Normal Distribution
</h1>
          
            <p class="page__meta"><i class="fa fa-clock-o" aria-hidden="true"></i> 


  
	  5 minute read
	
</p>
          
        
        
        
          <p class="page__date"><strong><i class="fa fa-fw fa-calendar" aria-hidden="true"></i> Published:</strong> <time datetime="2018-10-19T00:00:00-07:00">October 19, 2018</time></p>
        
        
             
        
    
        </header>
      

      <section class="page__content" itemprop="text">
        <p><img src="https://upload.wikimedia.org/wikipedia/commons/thumb/7/74/Normal_Distribution_PDF.svg/525px-Normal_Distribution_PDF.svg.png" alt="Normal Distribution" /></p>

<p>In every introductory statistics class, we learned about the normal distribution, which has Probability Density Function (PDF):</p>

<script type="math/tex; mode=display">\begin{align}\label{eq1}
    f(x | \mu, \sigma^2) = \frac{1}{\sqrt{2\pi \sigma^2}}e^{-\frac{(x-\mu)^2}{2\sigma^2}}
\end{align}</script>

<p>This looks like a fairly complicated equation, but the resulting graph (shown above) has some very cool properties (integrates to 1, represents real-valued random variables whose distributions are not known etc…). I’ve always wondered how this is derived, and I finally found some answers via great <a href="https://www.youtube.com/watch?v=cTyPuZ9-JZ0">YouTube videos</a> and <a href="https://math.stackexchange.com/questions/384893/how-was-the-normal-distribution-derived">online forums</a>. I will give an overview of the derivation here, based on YouTuber Mathoma’s amazing video (linked above).</p>

<h2 id="part-1-the-theory">Part 1: The Theory</h2>

<p>Mathoma gave a great analogy about how to understand this distribution: imagine you are throwing darts on a polar coordinate system, with the goal of hitting the center \((0,0)\). Now, given an arbitrary dart landing on coordinate \((r, \theta)\), we can also say that the coordinate is \((x, y)\) if we convert from polar to cartesian.</p>

<p>We have to make a couple assumptions here before moving forward. First, we assume that \(x\) and \(y\) are statistically independent. Second, we assume that the PDF is rotationally invariant, which means the distribution of where my dart lands only depends on the distance \(r\), of the dart to the center.</p>

<p>With those assumptions, I can define PDF \(\varphi(r) = f(x)f(y)\). This can be rewritten as</p>

<script type="math/tex; mode=display">\begin{align}\label{eq2}
    \varphi(\sqrt{x^2 + y^2}) = f(x)f(y)
\end{align}</script>

<p>Next, suppose \(y=0\). We will then have</p>

<div>
$$
\begin{align*}
    \varphi(\sqrt{x^2 + 0^2}) &amp;= f(x)f(0)\\
    \varphi(x) &amp;= f(x)\lambda, \text{ where $\lambda$ is a constant}
\end{align*}
$$
</div>

<p>Plugging this back into Eq \ref{eq2}, we have</p>

<script type="math/tex; mode=display">\begin{align}\label{eq3}
    \lambda f(\sqrt{x^2 + y^2}) = f(x)f(y)
\end{align}</script>

<p>Next, we will determine the expression for $f(x)$. First, we rewrite Eq \ref{eq3} as</p>

<script type="math/tex; mode=display">\begin{align*}
    \frac{\lambda f(\sqrt{x^2 + y^2})}{\lambda^2} = \frac{f(x)}{\lambda} \frac{f(y)}{\lambda}
\end{align*}</script>

<p>For simplicity in analyzing the equation, define $g(x) = \frac{f(x)}{\lambda}$. We now have</p>

<script type="math/tex; mode=display">\begin{align}\label{eq4}
    g(x)g(y) = g(\sqrt{x^2 + y^2})
\end{align}</script>

<p>What kind of function should $g$ be so that Eq \ref{eq4} is valid? Upon some inspection, we can see that $g$ should be an <strong>exponential function</strong>. Example: suppose we have $h(x) = e^x$, then $h(x)h(y) = e^xe^y = e^{x+y} = h(x+y)$. Similarly, let $g(x) = e^{Ax^2}$, where $A$ is a constant.</p>

<div>
$$
\begin{align*}
    g(x)g(y) &amp;= e^{Ax^2}e^{Ay^2}\\
    &amp;= e^{A(x^2 + y^2)}\\
    &amp;= e^{A(\sqrt{x^2 + y^2})^2}\\
    &amp;= g(\sqrt{x^2 + y^2})
\end{align*}
$$
</div>

<p>In turn, our PDF $f$ should be</p>

<script type="math/tex; mode=display">\begin{align}\label{eq5}
    f(x) = \lambda e^{Ax^2}
\end{align}</script>

<p><a href="https://www.desmos.com/calculator/hhsa3qpffi">Plotting this equation out</a> with $A=-1$ (more on why $A$ is negative later) and $\lambda=1$, we see that it takes a gaussian form!</p>

<h2 id="part-2-massaging-the-equation">Part 2: Massaging the Equation</h2>

<p>The remainder of this derivation serves to massage Eq \ref{eq5} into the class of gaussians we are interested in, the normal gaussian.</p>

<p>First, we introduce a constraint on the function: since we are modeling probability, it makes sense for $f(x)$ to integrate to $1$.</p>

<script type="math/tex; mode=display">\begin{align*}
    \int_{-\infty}^{\infty}f(x)dx = 1
\end{align*}</script>

<p>Instead of using constant $A$, we will set $A = -h^2$, where $h$ is a constant variable. There are several reasons for this: First, it makes sense for $A$ to be negative, because we want this function (which models the probability) to decrease as we move to $+\infty$. Second, the $-h^2$ form will help when we do the integration.</p>

<p>We determine the value of $h^2$:</p>

<div>
$$
\begin{align*}
    \int_{-\infty}^{\infty}\lambda e^{-h^2x^2}dx &amp;= 1\\
    \lambda\int_{-\infty}^{\infty}e^{-h^2x^2}dx &amp;= 1\\
\end{align*}
$$
</div>

<p>Perform <a href="https://www.wikiwand.com/en/Integration_by_substitution">u-substitution</a>, with $u = hx$, $du = hdx$, and $dx = \frac{1}{h}du$. We now get</p>

<script type="math/tex; mode=display">\begin{align}\label{eq6}
    \frac{\lambda}{h}\int_{-\infty}^{\infty}e^{-u^2}du = 1
\end{align}</script>

<p>Interestingly, the integral in Eq \ref{eq6} is actually famous (it has a name!). The <a href="https://en.wikipedia.org/wiki/Gaussian_integral">Gaussian integral</a>, also known as the Euler-Poisson integral, is equal to $\sqrt{\pi}$ (refer to link for the integral computation).</p>

<p>We can now compute $h^2$:</p>

<div>
$$
\begin{align*}
    \frac{\lambda}{h}\sqrt{\pi} &amp;= 1\\
    h &amp;= \lambda \sqrt{\pi}\\
    h^2 &amp;= \lambda^2\pi
\end{align*}
$$
</div>

<p>Eq \ref{eq5} becomes</p>

<script type="math/tex; mode=display">\begin{align}\label{eq7}
    f(x) = \lambda e^{-\pi \lambda^2x^2}
\end{align}</script>

<p>If we plot $f(x)$ using different $\lambda$ values, we see that as $\lambda$ increases, the variance $\sigma^2$ decreases, since more of the area is accumulated at $x=0$. See plots for <a href="https://www.desmos.com/calculator/lszecvqlgt">$\lambda=1$</a>, <a href="https://www.desmos.com/calculator/jpwcwodqef">$\lambda=2$</a>, <a href="https://www.desmos.com/calculator/uzdhdukutz">$\lambda=3$</a> as examples.</p>

<p>Next, we need to find the relationship between $\lambda$ and variance $\sigma^2$. From definition of <a href="https://www.wikiwand.com/en/Variance">variance</a>, we see that $Var(X) = E[(X - \mu)^2]$. In our case, $\mu$ is 0, so we have:</p>

<div>
$$
\begin{align*}
    Var(x) = \sigma^2 &amp;= \int_{-\infty}^{\infty}x^2 \lambda e^{-\pi \lambda^2x^2}dx \\
    &amp;= \lambda \int_{-\infty}^{\infty} x \cdot x \cdot e^{-\pi \lambda^2x^2}dx
\end{align*}
$$
</div>

<p>We will evaluate this integral via <a href="https://www.wikiwand.com/en/Integration_by_parts">integration by parts</a>. Recall that</p>

<script type="math/tex; mode=display">\begin{align*}
    \int udv = uv - \int vdu
\end{align*}</script>

<p>Let $u = x$, $du = dx$, $dv = xe^{-\pi \lambda^2x^2}dx$, $v = -\frac{1}{2\pi\lambda^2}e^{-\pi \lambda^2x^2}$:</p>

<div>
$$
\begin{align*}
    Var(x) = \sigma^2 &amp;= \lambda \left(x\left(-\frac{1}{2\pi\lambda^2}e^{-\pi \lambda^2x^2}\Biggr|_{-\infty}^{\infty}\right) - \int_{-\infty}^{\infty}\left(-\frac{1}{2\pi\lambda^2}e^{-\pi \lambda^2x^2}\right)dx\right)\\
    &amp;= \lambda \left((0) + \int_{-\infty}^{\infty}\frac{1}{2\pi\lambda^2}e^{-\pi \lambda^2x^2}dx\right)\\
    &amp;= \frac{1}{2\pi\lambda^2}\int_{-\infty}^{\infty}\lambda e^{-\pi \lambda^2x^2}dx
\end{align*}
$$
</div>

<p>The reason we switched the position of $\lambda$ and $\frac{1}{2\pi\lambda^2}$ is so we can massage the integral to be the form of the gaussian PDF, which we know integrates to 1. Now, with the equation simplified, we can solve for $\lambda$ in terms of $\sigma^2$.</p>

<div>
$$
\begin{align*}
    \sigma^2 &amp;= \frac{1}{2\pi\lambda^2}\\
    \lambda^2 &amp;= \frac{1}{\sigma^2 2\pi}\\
    \lambda &amp;= \frac{1}{\sqrt{2\pi\sigma^2}}
\end{align*}
$$
</div>

<p>$\lambda$ and $\sigma$ are inversely proportional, as expected. We can plug in our result here back into Eq \ref{eq7}:</p>

<div>
$$
\begin{align}\label{eq8}
    f(x) &amp;= \frac{1}{\sqrt{2\pi\sigma^2}}e^{-\pi \left(\frac{1}{(\sqrt{2\pi\sigma^2})^2}\right)x^2}\nonumber\\
    &amp;= \frac{1}{\sqrt{2\pi\sigma^2}}e^{-\frac{x^2}{2\sigma^2}}
\end{align}
$$
</div>

<p>We are almost done. The above equation has mean $\mu = 0$, but if we want to represent $f(x|\mu, \sigma^2)$, we need to add in $f(x-\mu)$. Therefore, our general PDF equation for the normal distribution is:</p>

<script type="math/tex; mode=display">\begin{align}\label{eq9}
    f(x | \mu, \sigma^2) = \frac{1}{\sqrt{2\pi \sigma^2}}e^{-\frac{(x-\mu)^2}{2\sigma^2}}
\end{align}</script>

<p>Eq \ref{eq9} matches Eq \ref{eq1}, and we are now done. $\blacksquare$</p>

        
      </section>

      <footer class="page__meta">
        
        


  




  
  
  

  <p class="page__taxonomy">
    <strong><i class="fa fa-fw fa-tags" aria-hidden="true"></i> Tags: </strong>
    <span itemprop="keywords">
    
      
      
      <a href="https://kfrankc.com/tags/#math" class="page__taxonomy-item" rel="tag">math</a><span class="sep">, </span>
    
      
      
      <a href="https://kfrankc.com/tags/#statistics" class="page__taxonomy-item" rel="tag">statistics</a>
    
    </span>
  </p>




      </footer>

      

<section class="page__share">
  
    <h4 class="page__share-title">Share on</h4>
  

  <a href="https://twitter.com/intent/tweet?text=https://kfrankc.com/posts/2018/10/19/normal-dist-derivation" class="btn btn--twitter" title="Share on Twitter"><i class="fa fa-fw fa-twitter" aria-hidden="true"></i><span> Twitter</span></a>

  <a href="https://www.facebook.com/sharer/sharer.php?u=https://kfrankc.com/posts/2018/10/19/normal-dist-derivation" class="btn btn--facebook" title="Share on Facebook"><i class="fa fa-fw fa-facebook" aria-hidden="true"></i><span> Facebook</span></a>

  <a href="https://plus.google.com/share?url=https://kfrankc.com/posts/2018/10/19/normal-dist-derivation" class="btn btn--google-plus" title="Share on Google Plus"><i class="fa fa-fw fa-google-plus" aria-hidden="true"></i><span> Google+</span></a>

  <a href="https://www.linkedin.com/shareArticle?mini=true&url=https://kfrankc.com/posts/2018/10/19/normal-dist-derivation" class="btn btn--linkedin" title="Share on LinkedIn"><i class="fa fa-fw fa-linkedin" aria-hidden="true"></i><span> LinkedIn</span></a>
</section>

      


  <nav class="pagination">
    
      <a href="https://kfrankc.com/posts/2018/10/09/mathjax" class="pagination--pager" title="Enabling MathJax
">Previous</a>
    
    
      <a href="https://kfrankc.com/posts/2018/10/29/normal-kurtosis-derivation" class="pagination--pager" title="Why is Kurtosis of Standard Normal Distribution 3?
">Next</a>
    
  </nav>

    </div>

    
      

<div class="page__comments">
  
  
    <h4 class="page__comments-title">Leave a Comment</h4>
    <section id="disqus_thread"></section>
  
</div>
    
  </article>

  
  
</div>


    </script>

    <div class="page__footer">
      <footer>
        <!-- start custom footer snippets -->
<!-- <a href="/sitemap/">Sitemap</a> -->
<!-- end custom footer snippets -->

        

<div class="page__footer-follow">
  <ul class="social-icons">
    
      <li><strong>Follow:</strong></li>
    
    
    
    
      <li><a href="http://github.com/kfrankc"><i class="fa fa-fw fa-github" aria-hidden="true"></i> GitHub</a></li>
    
    
    <li><a href="https://kfrankc.com/feed.xml"><i class="fa fa-fw fa-rss-square" aria-hidden="true"></i> Feed</a></li>
  </ul>
</div>

<div class="page__footer-copyright">&copy; 2018 Frank Chen. Powered by <a href="http://jekyllrb.com" rel="nofollow">Jekyll</a> &amp; <a href="https://github.com/academicpages/academicpages.github.io">AcademicPages</a>, a fork of <a href="https://mademistakes.com/work/minimal-mistakes-jekyll-theme/" rel="nofollow">Minimal Mistakes</a>.</div>

      </footer>
    </div>

    <script src="https://kfrankc.com/assets/js/main.min.js"></script>




  <script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-128201385-1', 'auto');
  ga('send', 'pageview');
</script>






  
  <script type="text/javascript">
  	/* * * CONFIGURATION VARIABLES: EDIT BEFORE PASTING INTO YOUR WEBPAGE * * */
  	var disqus_shortname = 'kfrankc-com';

  	/* * * DON'T EDIT BELOW THIS LINE * * */
  	(function() {
  		var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
  		dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
  		(document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
  	})();

  	/* * * DON'T EDIT BELOW THIS LINE * * */
  	(function () {
  		var s = document.createElement('script'); s.async = true;
  		s.type = 'text/javascript';
  		s.src = '//' + disqus_shortname + '.disqus.com/count.js';
  		(document.getElementsByTagName('HEAD')[0] || document.getElementsByTagName('BODY')[0]).appendChild(s);
  	}());
  </script>
  <noscript>Please enable JavaScript to view the <a href="http://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>






  </body>
</html>

